#!/usr/bin/env python3
"""
DumpItAll - –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è –∏ —Ä–µ–∑–µ—Ä–≤–Ω–æ–≥–æ –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏—è
–≤—Å–µ—Ö –±–∞–∑ –¥–∞–Ω–Ω—ã—Ö –Ω–∞ VPS (—Å–∏—Å—Ç–µ–º–Ω—ã–µ –∏ –≤ Docker –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞—Ö)

üóÑÔ∏è Dump It All - Find It, Dump It, Save It!
"""

import os
import json
import time
import subprocess
import schedule
import psutil
import docker
import sqlite3
from datetime import datetime
from googleapiclient.discovery import build
from googleapiclient.http import MediaFileUpload
from google.oauth2.service_account import Credentials
import logging
import glob
from pathlib import Path

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('backup.log'),
        logging.StreamHandler()
    ]
)

def print_logo():
    """–û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ ASCII –ª–æ–≥–æ—Ç–∏–ø–∞ DumpItAll"""
    logo = """
....................................................................................................
....................................................................................................
....................................................................................................
....................................................................................................
....................................................................................................
..............................................:-=**+-:..............................................
............................................=#%%%##%%%#+:...........................................
..........................................+%%%=:.....=%%%*..........................................
........................................-#%#=..........-#%#-........................................
.......................................=%%+..............+%%=.......................................
......................................+%%=................=%%+......................................
.....................................=%%=..................=%%+.....................................
....................................:%%+......:=++++=:......=%%-....................................
....................................#%*....:#%%%%%%%%%%*:....*%#....................................
...................................=%#-..-%%%%%%%%%%%%%%%%-..:#%+...................................
..................................:%%+.:#%%%%%%%%%%%%%%%%%%#:.+%%:..................................
..................................=%#-=%%%%%%%%%%%%%%%%%%%%%%=-#%+..................................
.................................:*%*-#%%%%%%%%%%%%%%%%%%%%%%#-*%*..................................
.................................:*%=+%%%%%%%%%%%%%%%%%%%%%%%%+=%#:.................................
.................................:*%+=%%%%%%%%%%%%%%%%%%%%%%%%=+%*..................................
..................................+%%=+%%%%%%%%%%%%%%%%%%%%%%+-#%=..................................
..............................:=#%%%%%=:#%%%%%%%%%%%%%%%%%%#:=%%%%%*=:..............................
.............................*%%*-:.-#%%+=%%%%%%%%%%%%%%%%==%%#-.:-*%%+.............................
...........................:#%+:......-#%%*+%%%%%%%%%%%%**%%#-......:*%#:...........................
..........................:*%*:.........-*%%%%%%%%%%%%%%%%*-.........:*%*:..........................
..........................=%%:............:+%%%%%%%%%%%%+:............:%%=..........................
.........................-%%:..-%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%#:..:%%-.........................
........................:%%=...+%=................................=%+...=%%:........................
.......................:#%+....=%+................................+%=....+%#:.......................
......................:*%#:....-%*:..............................:*%-....:#%*:......................
......................=%%:.:*+=:%*:............:+**=:............:*%:=+*:.:%%=......................
.....................:%%-...:-*%%#-............#%%%%*............-#%%*-:...-%%:.....................
.....................=%*:......:%%-............#%%%%*............-%%:......:*%=.....................
.....................=%#:......*%%=............:=**=.............=%%*:.....:*%=.....................
......................*%#-....=%%%+..............................+%%%=....:#%*:.....................
.......................=%%%#-:+%%%*..............................#%%%+:-*%%%+.......................
.........................-+#%%%%%%%******************************%%%%%%%#+-.........................
.............................:-+#%%=----------------------------=%%#+-:.............................
.................................-%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%#-.................................
....................................................................................................
..............######*:..................................-##-.:=-.....-###-...-%#-:%#-...............
..............#%+..=#%*:.:....:...:..::...::...:..:::...-%#-.=%*:...:*%#%*:..-%#-:%#-...............
..............#%+...:%%=+%*:.=%*.+%%##%%###%#-:%%%##%%+.-%#-+%%%#*:.-%#.*%=..-%#-:%#-...............
..............#%+...:%%=+%*:.=%*.+%+..*%*..*%=:%%-..-%%=-%#-.+%*...:%%-.-%%:.-%#-:%#-...............
..............#%+..:*%#:+%*:.=%*.+%+..*%+..*%=:%%-..-%%=-%#-.+%*...*%%%%%%%#:-%#-:%#-...............
..............#%%%%%#+:.-%%##%%*.+%+..*%+..*%=:%%%##%%+.-%#-.-#%%*=%%-...:#%+-%%*:%%#:..............
..............::::::......:-:.::.:::..:::..::::%%::--:...::....:-::::.....:::.:-:.:-:...............
..............................................:%%:..................................................
....................................................................................................
....................................................................................................
....................................................................................................
....................................................................................................
....................................................................................................
....................................................................................................
....................................................................................................
"""
    print(logo)
    print("üóÑÔ∏è DumpItAll - –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ —Ä–µ–∑–µ—Ä–≤–Ω–æ–≥–æ –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏—è –ë–î")
    print("üîç Find It, Dump It, Save It!")
    print("=" * 88)

class UniversalBackup:
    def __init__(self):
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ Google Drive
        self.CREDENTIALS_FILE = 'service-account-key.json'
        self.DRIVE_FOLDER_ID = os.getenv('DRIVE_FOLDER_ID', None)
        
        # –ü–∞–ø–∫–∞ –¥–ª—è —Ä–µ–∑–µ—Ä–≤–Ω—ã—Ö –∫–æ–ø–∏–π
        self.BACKUP_DIR = os.getenv('BACKUP_DIR', './backups')
        os.makedirs(self.BACKUP_DIR, exist_ok=True)
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–µ—Ä–≤–∏—Å–æ–≤
        self.drive_service = self._init_drive_service()
        self.docker_client = self._init_docker_client()
        
        # –û–±–Ω–∞—Ä—É–∂–µ–Ω–Ω—ã–µ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
        self.discovered_databases = []
        
        # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –¥–ª—è —Ä–∞–∑–Ω—ã—Ö –°–£–ë–î
        self.db_configs = {
            'postgresql': {
                'default_ports': [5432],
                'process_names': ['postgres', 'postgresql'],
                'backup_cmd': 'pg_dump',
                'docker_images': ['postgres', 'postgis/postgis', 'timescale/timescaledb']
            },
            'mysql': {
                'default_ports': [3306],
                'process_names': ['mysqld', 'mysql'],
                'backup_cmd': 'mysqldump',
                'docker_images': ['mysql', 'mariadb', 'percona']
            },
            'mongodb': {
                'default_ports': [27017],
                'process_names': ['mongod'],
                'backup_cmd': 'mongodump',
                'docker_images': ['mongo', 'mongodb/mongodb-community-server']
            },
            'redis': {
                'default_ports': [6379],
                'process_names': ['redis-server'],
                'backup_cmd': 'redis-cli',
                'docker_images': ['redis', 'bitnami/redis']
            },
            'sqlite': {
                'default_ports': [],
                'process_names': [],
                'backup_cmd': 'sqlite3',
                'docker_images': []
            }
        }

    def _init_drive_service(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–µ—Ä–≤–∏—Å–∞ Google Drive"""
        try:
            if os.path.exists(self.CREDENTIALS_FILE):
                credentials = Credentials.from_service_account_file(
                    self.CREDENTIALS_FILE,
                    scopes=['https://www.googleapis.com/auth/drive']
                )
                return build('drive', 'v3', credentials=credentials)
            else:
                logging.warning(f"–§–∞–π–ª {self.CREDENTIALS_FILE} –Ω–µ –Ω–∞–π–¥–µ–Ω")
                return None
        except Exception as e:
            logging.error(f"–û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ Google Drive API: {e}")
            return None

    def _init_docker_client(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Docker –∫–ª–∏–µ–Ω—Ç–∞"""
        try:
            return docker.from_env()
        except Exception as e:
            logging.warning(f"Docker –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω: {e}")
            return None

    def discover_system_databases(self):
        """–û–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ —Å–∏—Å—Ç–µ–º–Ω—ã—Ö –±–∞–∑ –¥–∞–Ω–Ω—ã—Ö"""
        logging.info("–°–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ —Å–∏—Å—Ç–µ–º–Ω—ã—Ö –ø—Ä–æ—Ü–µ—Å—Å–æ–≤...")
        
        system_dbs = []
        
        # –°–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–ø—É—â–µ–Ω–Ω—ã—Ö –ø—Ä–æ—Ü–µ—Å—Å–æ–≤
        for proc in psutil.process_iter(['pid', 'name', 'cmdline', 'connections']):
            try:
                proc_info = proc.info
                proc_name = proc_info['name'].lower()
                
                for db_type, config in self.db_configs.items():
                    if any(name in proc_name for name in config['process_names']):
                        db_info = self._analyze_system_process(proc, db_type, config)
                        if db_info:
                            system_dbs.append(db_info)
                            
            except (psutil.NoSuchProcess, psutil.AccessDenied):
                continue
        
        # –ü–æ–∏—Å–∫ SQLite —Ñ–∞–π–ª–æ–≤
        sqlite_dbs = self._find_sqlite_databases()
        system_dbs.extend(sqlite_dbs)
        
        logging.info(f"–ù–∞–π–¥–µ–Ω–æ {len(system_dbs)} —Å–∏—Å—Ç–µ–º–Ω—ã—Ö –±–∞–∑ –¥–∞–Ω–Ω—ã—Ö")
        return system_dbs

    def _analyze_system_process(self, proc, db_type, config):
        """–ê–Ω–∞–ª–∏–∑ —Å–∏—Å—Ç–µ–º–Ω–æ–≥–æ –ø—Ä–æ—Ü–µ—Å—Å–∞ –°–£–ë–î"""
        try:
            connections = proc.connections() if hasattr(proc, 'connections') else []
            cmdline = proc.cmdline()
            
            # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ—Ä—Ç–∞
            port = None
            for conn in connections:
                if conn.status == 'LISTEN' and conn.laddr.port in config['default_ports']:
                    port = conn.laddr.port
                    break
            
            if not port:
                port = config['default_ports'][0] if config['default_ports'] else None
            
            # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–æ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤ –∏ –¥–∞–Ω–Ω—ã—Ö
            data_dir = self._extract_data_directory(cmdline, db_type)
            
            return {
                'type': db_type,
                'source': 'system',
                'host': 'localhost',
                'port': port,
                'pid': proc.pid,
                'data_dir': data_dir,
                'cmdline': ' '.join(cmdline) if cmdline else '',
                'databases': self._get_database_list(db_type, 'localhost', port)
            }
            
        except Exception as e:
            logging.error(f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –ø—Ä–æ—Ü–µ—Å—Å–∞ {proc.pid}: {e}")
            return None

    def _extract_data_directory(self, cmdline, db_type):
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –¥–∞–Ω–Ω—ã—Ö –∏–∑ –∫–æ–º–∞–Ω–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏"""
        if not cmdline:
            return None
            
        cmdline_str = ' '.join(cmdline)
        
        patterns = {
            'postgresql': ['-D', '--data-directory'],
            'mysql': ['--datadir'],
            'mongodb': ['--dbpath']
        }
        
        if db_type in patterns:
            for pattern in patterns[db_type]:
                if pattern in cmdline_str:
                    parts = cmdline_str.split()
                    try:
                        idx = parts.index(pattern)
                        if idx + 1 < len(parts):
                            return parts[idx + 1]
                    except ValueError:
                        continue
        
        return None

    def discover_docker_databases(self):
        """–û–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –±–∞–∑ –¥–∞–Ω–Ω—ã—Ö –≤ Docker –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞—Ö"""
        if not self.docker_client:
            return []
            
        logging.info("–°–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ Docker –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–æ–≤...")
        docker_dbs = []
        
        try:
            containers = self.docker_client.containers.list()
            
            for container in containers:
                db_info = self._analyze_docker_container(container)
                if db_info:
                    docker_dbs.extend(db_info)
                    
        except Exception as e:
            logging.error(f"–û—à–∏–±–∫–∞ —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è Docker: {e}")
        
        logging.info(f"–ù–∞–π–¥–µ–Ω–æ {len(docker_dbs)} –±–∞–∑ –¥–∞–Ω–Ω—ã—Ö –≤ Docker")
        return docker_dbs

    def _analyze_docker_container(self, container):
        """–ê–Ω–∞–ª–∏–∑ Docker –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞"""
        try:
            image_name = container.image.tags[0] if container.image.tags else ''
            container_info = []
            
            for db_type, config in self.db_configs.items():
                if any(img in image_name.lower() for img in config['docker_images']):
                    
                    # –ü–æ–ª—É—á–µ–Ω–∏–µ –ø–æ—Ä—Ç–æ–≤
                    ports = container.attrs.get('NetworkSettings', {}).get('Ports', {})
                    exposed_ports = []
                    
                    for port_info in ports.values():
                        if port_info:
                            for binding in port_info:
                                if binding.get('HostPort'):
                                    exposed_ports.append(int(binding['HostPort']))
                    
                    # –ü–æ–ª—É—á–µ–Ω–∏–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è
                    env_vars = {}
                    for env in container.attrs.get('Config', {}).get('Env', []):
                        if '=' in env:
                            key, value = env.split('=', 1)
                            env_vars[key] = value
                    
                    # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —É—á–µ—Ç–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
                    credentials = self._extract_docker_credentials(env_vars, db_type)
                    
                    # –ü–æ–ª—É—á–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ –±–∞–∑ –¥–∞–Ω–Ω—ã—Ö
                    databases = self._get_docker_database_list(container, db_type, credentials)
                    
                    container_info.append({
                        'type': db_type,
                        'source': 'docker',
                        'container_id': container.id,
                        'container_name': container.name,
                        'image': image_name,
                        'host': 'localhost',
                        'ports': exposed_ports,
                        'credentials': credentials,
                        'databases': databases,
                        'volumes': self._get_container_volumes(container)
                    })
            
            return container_info
            
        except Exception as e:
            logging.error(f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞ {container.name}: {e}")
            return []

    def _extract_docker_credentials(self, env_vars, db_type):
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —É—á–µ—Ç–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –∏–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è"""
        credentials = {}
        
        env_mappings = {
            'postgresql': {
                'user': ['POSTGRES_USER', 'POSTGRESQL_USER'],
                'password': ['POSTGRES_PASSWORD', 'POSTGRESQL_PASSWORD'],
                'database': ['POSTGRES_DB', 'POSTGRESQL_DATABASE']
            },
            'mysql': {
                'user': ['MYSQL_USER', 'MARIADB_USER'],
                'password': ['MYSQL_PASSWORD', 'MARIADB_PASSWORD', 'MYSQL_ROOT_PASSWORD'],
                'database': ['MYSQL_DATABASE', 'MARIADB_DATABASE']
            },
            'mongodb': {
                'user': ['MONGO_INITDB_ROOT_USERNAME'],
                'password': ['MONGO_INITDB_ROOT_PASSWORD'],
                'database': ['MONGO_INITDB_DATABASE']
            }
        }
        
        if db_type in env_mappings:
            mapping = env_mappings[db_type]
            for cred_type, env_keys in mapping.items():
                for env_key in env_keys:
                    if env_key in env_vars:
                        credentials[cred_type] = env_vars[env_key]
                        break
        
        return credentials

    def _get_container_volumes(self, container):
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ —Ç–æ–º–∞—Ö –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞"""
        volumes = []
        mounts = container.attrs.get('Mounts', [])
        
        for mount in mounts:
            volumes.append({
                'source': mount.get('Source'),
                'destination': mount.get('Destination'),
                'type': mount.get('Type')
            })
        
        return volumes

    def _find_sqlite_databases(self):
        """–ü–æ–∏—Å–∫ SQLite —Ñ–∞–π–ª–æ–≤ –≤ —Å–∏—Å—Ç–µ–º–µ"""
        sqlite_dbs = []
        search_paths = [
            '/var/lib',
            '/opt',
            '/home',
            '/usr/local',
            '/tmp'
        ]
        
        sqlite_extensions = ['*.db', '*.sqlite', '*.sqlite3']
        
        for search_path in search_paths:
            if os.path.exists(search_path):
                for ext in sqlite_extensions:
                    try:
                        files = glob.glob(os.path.join(search_path, '**', ext), recursive=True)
                        for file_path in files:
                            if self._is_sqlite_database(file_path):
                                sqlite_dbs.append({
                                    'type': 'sqlite',
                                    'source': 'system',
                                    'file_path': file_path,
                                    'size': os.path.getsize(file_path),
                                    'databases': [os.path.basename(file_path)]
                                })
                    except (PermissionError, OSError):
                        continue
        
        return sqlite_dbs

    def _is_sqlite_database(self, file_path):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —Ñ–∞–π–ª –±–∞–∑–æ–π –¥–∞–Ω–Ω—ã—Ö SQLite"""
        try:
            with open(file_path, 'rb') as f:
                header = f.read(16)
                return header.startswith(b'SQLite format 3\x00')
        except:
            return False

    def _get_database_list(self, db_type, host, port):
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ –±–∞–∑ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Å–∏—Å—Ç–µ–º–Ω—ã—Ö –°–£–ë–î"""
        databases = []
        
        try:
            if db_type == 'postgresql':
                cmd = ['psql', '-h', host, '-p', str(port), '-U', 'postgres', '-l', '-t']
                result = subprocess.run(cmd, capture_output=True, text=True, timeout=10)
                if result.returncode == 0:
                    for line in result.stdout.split('\n'):
                        if '|' in line:
                            db_name = line.split('|')[0].strip()
                            if db_name and db_name not in ['template0', 'template1']:
                                databases.append(db_name)
            
            elif db_type == 'mysql':
                cmd = ['mysql', '-h', host, '-P', str(port), '-e', 'SHOW DATABASES;']
                result = subprocess.run(cmd, capture_output=True, text=True, timeout=10)
                if result.returncode == 0:
                    for line in result.stdout.split('\n'):
                        db_name = line.strip()
                        if db_name and db_name not in ['Database', 'information_schema', 'performance_schema', 'mysql', 'sys']:
                            databases.append(db_name)
            
            elif db_type == 'mongodb':
                cmd = ['mongo', '--host', f"{host}:{port}", '--eval', 'db.adminCommand("listDatabases").databases.forEach(function(db) { print(db.name) })']
                result = subprocess.run(cmd, capture_output=True, text=True, timeout=10)
                if result.returncode == 0:
                    for line in result.stdout.split('\n'):
                        db_name = line.strip()
                        if db_name and db_name not in ['admin', 'local', 'config']:
                            databases.append(db_name)
                            
        except Exception as e:
            logging.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ –ë–î –¥–ª—è {db_type}: {e}")
        
        return databases

    def _get_docker_database_list(self, container, db_type, credentials):
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ –±–∞–∑ –¥–∞–Ω–Ω—ã—Ö –≤ Docker –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–µ"""
        databases = []
        
        try:
            if db_type == 'postgresql':
                cmd = ['psql', '-U', credentials.get('user', 'postgres'), '-l', '-t']
            elif db_type == 'mysql':
                cmd = ['mysql', '-u', credentials.get('user', 'root'), '-e', 'SHOW DATABASES;']
            elif db_type == 'mongodb':
                cmd = ['mongo', '--eval', 'db.adminCommand("listDatabases").databases.forEach(function(db) { print(db.name) })']
            else:
                return []
            
            if credentials.get('password'):
                if db_type == 'postgresql':
                    env = {'PGPASSWORD': credentials['password']}
                elif db_type == 'mysql':
                    cmd.extend(['-p' + credentials['password']])
                    env = {}
                else:
                    env = {}
            else:
                env = {}
            
            result = container.exec_run(cmd, environment=env)
            if result.exit_code == 0:
                output = result.output.decode('utf-8')
                
                if db_type == 'postgresql':
                    for line in output.split('\n'):
                        if '|' in line:
                            db_name = line.split('|')[0].strip()
                            if db_name and db_name not in ['template0', 'template1']:
                                databases.append(db_name)
                
                elif db_type == 'mysql':
                    for line in output.split('\n'):
                        db_name = line.strip()
                        if db_name and db_name not in ['Database', 'information_schema', 'performance_schema', 'mysql', 'sys']:
                            databases.append(db_name)
                
                elif db_type == 'mongodb':
                    for line in output.split('\n'):
                        db_name = line.strip()
                        if db_name and db_name not in ['admin', 'local', 'config']:
                            databases.append(db_name)
                            
        except Exception as e:
            logging.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ –ë–î –≤ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–µ {container.name}: {e}")
        
        return databases

    def scan_network_ports(self):
        """–°–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ —Å–µ—Ç–µ–≤—ã—Ö –ø–æ—Ä—Ç–æ–≤ –¥–ª—è –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è –°–£–ë–î"""
        logging.info("–°–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ —Å–µ—Ç–µ–≤—ã—Ö –ø–æ—Ä—Ç–æ–≤...")
        
        port_databases = []
        
        # –ü–æ–ª—É—á–µ–Ω–∏–µ –≤—Å–µ—Ö –æ—Ç–∫—Ä—ã—Ç—ã—Ö –ø–æ—Ä—Ç–æ–≤
        open_ports = self._get_open_ports()
        
        # –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ –ø–æ—Ä—Ç—ã –°–£–ë–î –¥–ª—è –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–Ω–æ–≥–æ —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è
        priority_ports = {
            5432: 'postgresql',
            3306: 'mysql',
            27017: 'mongodb', 
            6379: 'redis',
            1521: 'oracle',
            1433: 'mssql',
            50000: 'db2',
            8086: 'influxdb',
            9200: 'elasticsearch',
            5984: 'couchdb'
        }
        
        # –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ –ø–æ—Ä—Ç—ã –ë–î
        for port, expected_type in priority_ports.items():
            if port in open_ports:
                db_info = self._probe_database_port('localhost', port, expected_type)
                if db_info:
                    port_databases.append(db_info)
                    logging.info(f"–û–±–Ω–∞—Ä—É–∂–µ–Ω–∞ {expected_type} –Ω–∞ –ø–æ—Ä—Ç—É {port}")
        
        # –ó–∞—Ç–µ–º –ø—Ä–æ–≤–µ—Ä—è–µ–º –≤—Å–µ –æ—Å—Ç–∞–ª—å–Ω—ã–µ –æ—Ç–∫—Ä—ã—Ç—ã–µ –ø–æ—Ä—Ç—ã
        for port in open_ports:
            if port not in priority_ports:
                # –ü—ã—Ç–∞–µ–º—Å—è –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å —Ç–∏–ø –ë–î –ø–æ –±–∞–Ω–Ω–µ—Ä—É/–æ—Ç–∫–ª–∏–∫—É
                db_info = self._probe_unknown_port('localhost', port)
                if db_info:
                    port_databases.append(db_info)
                    logging.info(f"–û–±–Ω–∞—Ä—É–∂–µ–Ω–∞ –ë–î {db_info['type']} –Ω–∞ –ø–æ—Ä—Ç—É {port}")
        
        logging.info(f"–û–±–Ω–∞—Ä—É–∂–µ–Ω–æ {len(port_databases)} –ë–î —á–µ—Ä–µ–∑ —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–æ—Ä—Ç–æ–≤")
        return port_databases

    def _get_open_ports(self):
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ –≤—Å–µ—Ö –æ—Ç–∫—Ä—ã—Ç—ã—Ö –ø–æ—Ä—Ç–æ–≤"""
        open_ports = set()
        
        try:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º psutil –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è —Å–µ—Ç–µ–≤—ã—Ö —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–π
            connections = psutil.net_connections(kind='inet')
            
            for conn in connections:
                if conn.status == 'LISTEN' and conn.laddr:
                    port = conn.laddr.port
                    # –ò—Å–∫–ª—é—á–∞–µ–º —Å–∏—Å—Ç–µ–º–Ω—ã–µ –ø–æ—Ä—Ç—ã < 1024 (–∫—Ä–æ–º–µ –∏–∑–≤–µ—Å—Ç–Ω—ã—Ö –ë–î)
                    if port >= 1024 or port in [80, 443, 22, 21, 25, 53, 110, 143, 993, 995]:
                        continue
                    if port in [5432, 3306, 27017, 6379, 1521, 1433, 50000, 8086, 9200, 5984]:
                        open_ports.add(port)
                    elif port >= 1024:
                        open_ports.add(port)
            
            # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ —Å–∫–∞–Ω–∏—Ä—É–µ–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ –ø–æ—Ä—Ç—ã –ë–î, –¥–∞–∂–µ –µ—Å–ª–∏ psutil –∏—Ö –Ω–µ –≤–∏–¥–∏—Ç
            standard_db_ports = [5432, 3306, 27017, 6379, 1521, 1433, 50000, 8086, 9200, 5984]
            for port in standard_db_ports:
                if self._is_port_open('localhost', port):
                    open_ports.add(port)
                    
        except Exception as e:
            logging.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –æ—Ç–∫—Ä—ã—Ç—ã—Ö –ø–æ—Ä—Ç–æ–≤: {e}")
        
        return open_ports

    def _is_port_open(self, host, port):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞, –æ—Ç–∫—Ä—ã—Ç –ª–∏ –ø–æ—Ä—Ç"""
        import socket
        try:
            with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as sock:
                sock.settimeout(2)
                result = sock.connect_ex((host, port))
                return result == 0
        except:
            return False

    def _probe_database_port(self, host, port, expected_type):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –ø–æ—Ä—Ç–∞ –Ω–∞ –Ω–∞–ª–∏—á–∏–µ –æ–∂–∏–¥–∞–µ–º–æ–π –°–£–ë–î"""
        try:
            if expected_type == 'postgresql':
                return self._probe_postgresql(host, port)
            elif expected_type == 'mysql':
                return self._probe_mysql(host, port)
            elif expected_type == 'mongodb':
                return self._probe_mongodb(host, port)
            elif expected_type == 'redis':
                return self._probe_redis(host, port)
            elif expected_type == 'oracle':
                return self._probe_oracle(host, port)
            elif expected_type == 'mssql':
                return self._probe_mssql(host, port)
            else:
                return None
        except Exception as e:
            logging.debug(f"–û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ {expected_type} –Ω–∞ {host}:{port}: {e}")
            return None

    def _probe_unknown_port(self, host, port):
        """–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç–∏–ø–∞ –ë–î –Ω–∞ –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ–º –ø–æ—Ä—Ç—É"""
        import socket
        
        try:
            with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as sock:
                sock.settimeout(5)
                sock.connect((host, port))
                
                # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –ø—É—Å—Ç–æ–π –∑–∞–ø—Ä–æ—Å –∏ –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç
                try:
                    sock.send(b'\n')
                    response = sock.recv(1024)
                    
                    response_str = response.decode('utf-8', errors='ignore').lower()
                    
                    # –ê–Ω–∞–ª–∏–∑ –±–∞–Ω–Ω–µ—Ä–æ–≤/–æ—Ç–∫–ª–∏–∫–æ–≤
                    if 'postgresql' in response_str or 'postgres' in response_str:
                        return self._probe_postgresql(host, port)
                    elif 'mysql' in response_str or 'mariadb' in response_str:
                        return self._probe_mysql(host, port)
                    elif 'mongodb' in response_str or 'mongo' in response_str:
                        return self._probe_mongodb(host, port)
                    elif '+pong' in response_str or 'redis' in response_str:
                        return self._probe_redis(host, port)
                    elif 'elasticsearch' in response_str:
                        return self._probe_elasticsearch(host, port)
                    elif 'couchdb' in response_str:
                        return self._probe_couchdb(host, port)
                        
                except:
                    pass
                    
        except Exception as e:
            logging.debug(f"–ù–µ —É–¥–∞–ª–æ—Å—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å —Ç–∏–ø –ë–î –Ω–∞ {host}:{port}: {e}")
        
        return None

    def _probe_postgresql(self, host, port):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ PostgreSQL"""
        try:
            # –ü—ã—Ç–∞–µ–º—Å—è –ø–æ–¥–∫–ª—é—á–∏—Ç—å—Å—è –∫ PostgreSQL
            import subprocess
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –±–µ–∑ –ø–∞—Ä–æ–ª—è
            cmd = ['psql', '-h', host, '-p', str(port), '-U', 'postgres', '-d', 'template1', '-c', '\\l', '-t']
            result = subprocess.run(cmd, capture_output=True, text=True, timeout=10,
                                  env={**os.environ, 'PGPASSWORD': ''})
            
            databases = []
            if result.returncode == 0:
                for line in result.stdout.split('\n'):
                    if '|' in line:
                        db_name = line.split('|')[0].strip()
                        if db_name and db_name not in ['template0', 'template1']:
                            databases.append(db_name)
            
            return {
                'type': 'postgresql',
                'source': 'network_scan',
                'host': host,
                'port': port,
                'databases': databases,
                'connection_tested': result.returncode == 0,
                'auth_method': 'trust' if result.returncode == 0 else 'required'
            }
            
        except Exception as e:
            logging.debug(f"–û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ PostgreSQL {host}:{port}: {e}")
            # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –±–∞–∑–æ–≤—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –¥–∞–∂–µ –µ—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ –ë–î
            return {
                'type': 'postgresql',
                'source': 'network_scan',
                'host': host,
                'port': port,
                'databases': [],
                'connection_tested': False,
                'auth_method': 'unknown'
            }

    def _probe_mysql(self, host, port):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ MySQL/MariaDB"""
        try:
            import subprocess
            
            # –ü—ã—Ç–∞–µ–º—Å—è –ø–æ–¥–∫–ª—é—á–∏—Ç—å—Å—è –∫ MySQL
            cmd = ['mysql', '-h', host, '-P', str(port), '-u', 'root', '-e', 'SHOW DATABASES;']
            result = subprocess.run(cmd, capture_output=True, text=True, timeout=10)
            
            databases = []
            if result.returncode == 0:
                for line in result.stdout.split('\n'):
                    db_name = line.strip()
                    if db_name and db_name not in ['Database', 'information_schema', 'performance_schema', 'mysql', 'sys']:
                        databases.append(db_name)
            
            return {
                'type': 'mysql',
                'source': 'network_scan', 
                'host': host,
                'port': port,
                'databases': databases,
                'connection_tested': result.returncode == 0,
                'auth_method': 'no_password' if result.returncode == 0 else 'required'
            }
            
        except Exception as e:
            logging.debug(f"–û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ MySQL {host}:{port}: {e}")
            return {
                'type': 'mysql',
                'source': 'network_scan',
                'host': host,
                'port': port,
                'databases': [],
                'connection_tested': False,
                'auth_method': 'unknown'
            }

    def _probe_mongodb(self, host, port):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ MongoDB"""
        try:
            import subprocess
            
            # –ü—ã—Ç–∞–µ–º—Å—è –ø–æ–¥–∫–ª—é—á–∏—Ç—å—Å—è –∫ MongoDB
            cmd = ['mongo', '--host', f"{host}:{port}", '--eval', 
                   'db.adminCommand("listDatabases").databases.forEach(function(db) { print(db.name) })', 
                   '--quiet']
            result = subprocess.run(cmd, capture_output=True, text=True, timeout=10)
            
            databases = []
            if result.returncode == 0:
                for line in result.stdout.split('\n'):
                    db_name = line.strip()
                    if db_name and db_name not in ['admin', 'local', 'config']:
                        databases.append(db_name)
            
            return {
                'type': 'mongodb',
                'source': 'network_scan',
                'host': host,
                'port': port,
                'databases': databases,
                'connection_tested': result.returncode == 0,
                'auth_method': 'no_auth' if result.returncode == 0 else 'required'
            }
            
        except Exception as e:
            logging.debug(f"–û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ MongoDB {host}:{port}: {e}")
            return {
                'type': 'mongodb',
                'source': 'network_scan',
                'host': host,
                'port': port,
                'databases': [],
                'connection_tested': False,
                'auth_method': 'unknown'
            }

    def _probe_redis(self, host, port):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ Redis"""
        try:
            import subprocess
            
            # –ü—ã—Ç–∞–µ–º—Å—è –ø–æ–¥–∫–ª—é—á–∏—Ç—å—Å—è –∫ Redis
            cmd = ['redis-cli', '-h', host, '-p', str(port), 'ping']
            result = subprocess.run(cmd, capture_output=True, text=True, timeout=5)
            
            if result.returncode == 0 and 'PONG' in result.stdout:
                # –ü–æ–ª—É—á–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ Redis
                info_cmd = ['redis-cli', '-h', host, '-p', str(port), 'info', 'keyspace']
                info_result = subprocess.run(info_cmd, capture_output=True, text=True, timeout=5)
                
                databases = []
                if info_result.returncode == 0:
                    for line in info_result.stdout.split('\n'):
                        if line.startswith('db'):
                            db_num = line.split(':')[0]
                            databases.append(db_num)
                
                if not databases:
                    databases = ['db0']  # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é Redis –∏—Å–ø–æ–ª—å–∑—É–µ—Ç db0
                
                return {
                    'type': 'redis',
                    'source': 'network_scan',
                    'host': host,
                    'port': port,
                    'databases': databases,
                    'connection_tested': True,
                    'auth_method': 'no_auth'
                }
            
        except Exception as e:
            logging.debug(f"–û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ Redis {host}:{port}: {e}")
        
        return None

    def _probe_elasticsearch(self, host, port):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ Elasticsearch"""
        try:
            import requests
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º Elasticsearch API
            response = requests.get(f'http://{host}:{port}/', timeout=5)
            if response.status_code == 200 and 'elasticsearch' in response.text.lower():
                
                # –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ –∏–Ω–¥–µ–∫—Å–æ–≤
                indices_response = requests.get(f'http://{host}:{port}/_cat/indices?format=json', timeout=5)
                databases = []
                if indices_response.status_code == 200:
                    indices = indices_response.json()
                    databases = [idx['index'] for idx in indices if not idx['index'].startswith('.')]
                
                return {
                    'type': 'elasticsearch',
                    'source': 'network_scan',
                    'host': host,
                    'port': port,
                    'databases': databases,
                    'connection_tested': True,
                    'auth_method': 'no_auth'
                }
                
        except Exception as e:
            logging.debug(f"–û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ Elasticsearch {host}:{port}: {e}")
        
        return None

    def _probe_couchdb(self, host, port):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ CouchDB"""
        try:
            import requests
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º CouchDB API
            response = requests.get(f'http://{host}:{port}/', timeout=5)
            if response.status_code == 200 and 'couchdb' in response.text.lower():
                
                # –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ –±–∞–∑ –¥–∞–Ω–Ω—ã—Ö
                dbs_response = requests.get(f'http://{host}:{port}/_all_dbs', timeout=5)
                databases = []
                if dbs_response.status_code == 200:
                    databases = [db for db in dbs_response.json() if not db.startswith('_')]
                
                return {
                    'type': 'couchdb',
                    'source': 'network_scan',
                    'host': host,
                    'port': port,
                    'databases': databases,
                    'connection_tested': True,
                    'auth_method': 'no_auth'
                }
                
        except Exception as e:
            logging.debug(f"–û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ CouchDB {host}:{port}: {e}")
        
        return None

    def _probe_oracle(self, host, port):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ Oracle Database"""
        try:
            # Oracle —Ç—Ä–µ–±—É–µ—Ç —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–π –∫–ª–∏–µ–Ω—Ç, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –±–∞–∑–æ–≤—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
            return {
                'type': 'oracle',
                'source': 'network_scan',
                'host': host,
                'port': port,
                'databases': [],
                'connection_tested': False,
                'auth_method': 'unknown',
                'note': 'Oracle detected by port, manual configuration required'
            }
        except Exception as e:
            logging.debug(f"–û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ Oracle {host}:{port}: {e}")
        
        return None

    def _probe_mssql(self, host, port):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ Microsoft SQL Server"""
        try:
            # SQL Server —Ç—Ä–µ–±—É–µ—Ç —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–π –∫–ª–∏–µ–Ω—Ç, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –±–∞–∑–æ–≤—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
            return {
                'type': 'mssql',
                'source': 'network_scan',
                'host': host,
                'port': port,
                'databases': [],
                'connection_tested': False,
                'auth_method': 'unknown',
                'note': 'SQL Server detected by port, manual configuration required'
            }
        except Exception as e:
            logging.debug(f"–û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ SQL Server {host}:{port}: {e}")
        
        return None

    def discover_all_databases(self):
        """–û–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –≤—Å–µ—Ö –±–∞–∑ –¥–∞–Ω–Ω—ã—Ö"""
        logging.info("=" * 60)
        logging.info("–ù–∞—á–∞–ª–æ –ø–æ–ª–Ω–æ–≥–æ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è –±–∞–∑ –¥–∞–Ω–Ω—ã—Ö")
        logging.info("=" * 60)
        
        self.discovered_databases = []
        
        # 1. –°–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ —Å–µ—Ç–µ–≤—ã—Ö –ø–æ—Ä—Ç–æ–≤ (–ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç)
        logging.info("üîç –≠—Ç–∞–ø 1: –°–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ —Å–µ—Ç–µ–≤—ã—Ö –ø–æ—Ä—Ç–æ–≤")
        port_dbs = self.scan_network_ports()
        self.discovered_databases.extend(port_dbs)
        
        # 2. –°–∏—Å—Ç–µ–º–Ω—ã–µ –ø—Ä–æ—Ü–µ—Å—Å—ã –ë–î
        logging.info("üñ•Ô∏è –≠—Ç–∞–ø 2: –ê–Ω–∞–ª–∏–∑ —Å–∏—Å—Ç–µ–º–Ω—ã—Ö –ø—Ä–æ—Ü–µ—Å—Å–æ–≤")
        system_dbs = self.discover_system_databases()
        self.discovered_databases.extend(system_dbs)
        
        # 3. Docker –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä—ã
        logging.info("üê≥ –≠—Ç–∞–ø 3: –°–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ Docker –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–æ–≤")
        docker_dbs = self.discover_docker_databases()
        self.discovered_databases.extend(docker_dbs)
        
        # 4. –£–¥–∞–ª–µ–Ω–∏–µ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤
        self._remove_duplicate_databases()
        
        logging.info("=" * 60)
        logging.info(f"–û–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ: {len(self.discovered_databases)} —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –ë–î")
        logging.info("=" * 60)
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ø–æ–¥—Ä–æ–±–Ω–æ–≥–æ –æ—Ç—á–µ—Ç–∞
        self._save_discovery_report()
        self._print_discovery_summary()
        
        return self.discovered_databases

    def _remove_duplicate_databases(self):
        """–£–¥–∞–ª–µ–Ω–∏–µ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ –ë–î"""
        unique_dbs = []
        seen = set()
        
        for db in self.discovered_databases:
            # –°–æ–∑–¥–∞–µ–º –∫–ª—é—á –¥–ª—è –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏–∏ —É–Ω–∏–∫–∞–ª—å–Ω–æ–π –ë–î
            key = f"{db['type']}:{db.get('host', 'localhost')}:{db.get('port', 'unknown')}"
            
            if key not in seen:
                seen.add(key)
                unique_dbs.append(db)
            else:
                # –û–±—ä–µ–¥–∏–Ω—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ —Ä–∞–∑–Ω—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤
                existing_db = next(d for d in unique_dbs if 
                                 f"{d['type']}:{d.get('host', 'localhost')}:{d.get('port', 'unknown')}" == key)
                
                # –û–±—ä–µ–¥–∏–Ω—è–µ–º —Å–ø–∏—Å–∫–∏ –±–∞–∑ –¥–∞–Ω–Ω—ã—Ö
                existing_databases = set(existing_db.get('databases', []))
                new_databases = set(db.get('databases', []))
                existing_db['databases'] = list(existing_databases.union(new_databases))
                
                # –û–±–Ω–æ–≤–ª—è–µ–º –∏—Å—Ç–æ—á–Ω–∏–∫–∏
                sources = existing_db.get('sources', [existing_db.get('source', 'unknown')])
                if db.get('source') not in sources:
                    sources.append(db.get('source'))
                existing_db['sources'] = sources
        
        self.discovered_databases = unique_dbs
        logging.info(f"–ü–æ—Å–ª–µ —É–¥–∞–ª–µ–Ω–∏—è –¥—É–±–ª–∏–∫–∞—Ç–æ–≤: {len(unique_dbs)} —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –ë–î")

    def _print_discovery_summary(self):
        """–í—ã–≤–æ–¥ –∫—Ä–∞—Ç–∫–æ–≥–æ –æ—Ç—á–µ—Ç–∞ –æ–± –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏–∏"""
        logging.info("\nüìä –ö–†–ê–¢–ö–ò–ô –û–¢–ß–ï–¢ –û–ë –û–ë–ù–ê–†–£–ñ–ï–ù–ò–ò:")
        
        by_type = {}
        by_source = {}
        total_databases = 0
        
        for db in self.discovered_databases:
            db_type = db['type']
            sources = db.get('sources', [db.get('source', 'unknown')])
            databases_count = len(db.get('databases', []))
            
            by_type[db_type] = by_type.get(db_type, 0) + 1
            total_databases += databases_count
            
            for source in sources:
                by_source[source] = by_source.get(source, 0) + 1
        
        logging.info(f"üìà –í—Å–µ–≥–æ –°–£–ë–î: {len(self.discovered_databases)}")
        logging.info(f"üìä –í—Å–µ–≥–æ –±–∞–∑ –¥–∞–Ω–Ω—ã—Ö: {total_databases}")
        
        logging.info("\nüîß –ü–æ —Ç–∏–ø–∞–º –°–£–ë–î:")
        for db_type, count in sorted(by_type.items()):
            logging.info(f"  {db_type}: {count}")
        
        logging.info("\nüîç –ü–æ –∏—Å—Ç–æ—á–Ω–∏–∫–∞–º –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è:")
        for source, count in sorted(by_source.items()):
            logging.info(f"  {source}: {count}")
        
        logging.info("\nüíæ –ü–æ–¥—Ä–æ–±–Ω—ã–π –æ—Ç—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ discovery_report_*.json")

    def _save_discovery_report(self):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ—Ç—á–µ—Ç–∞ –æ–± –æ–±–Ω–∞—Ä—É–∂–µ–Ω–Ω—ã—Ö –ë–î"""
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        report_file = os.path.join(self.BACKUP_DIR, f'discovery_report_{timestamp}.json')
        
        try:
            with open(report_file, 'w', encoding='utf-8') as f:
                json.dump(self.discovered_databases, f, indent=2, ensure_ascii=False, default=str)
            logging.info(f"–û—Ç—á–µ—Ç –æ–± –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {report_file}")
        except Exception as e:
            logging.error(f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –æ—Ç—á–µ—Ç–∞: {e}")

    def backup_database(self, db_info):
        """–°–æ–∑–¥–∞–Ω–∏–µ —Ä–µ–∑–µ—Ä–≤–Ω–æ–π –∫–æ–ø–∏–∏ –æ—Ç–¥–µ–ª—å–Ω–æ–π –ë–î"""
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        
        if db_info['source'] == 'system':
            return self._backup_system_database(db_info, timestamp)
        elif db_info['source'] == 'docker':
            return self._backup_docker_database(db_info, timestamp)
        
        return None

    def backup_database(self, db_info):
        """–°–æ–∑–¥–∞–Ω–∏–µ —Ä–µ–∑–µ—Ä–≤–Ω–æ–π –∫–æ–ø–∏–∏ –æ—Ç–¥–µ–ª—å–Ω–æ–π –ë–î"""
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        
        if db_info['source'] == 'system' or db_info['source'] == 'network_scan':
            return self._backup_system_database(db_info, timestamp)
        elif db_info['source'] == 'docker':
            return self._backup_docker_database(db_info, timestamp)
        
        return None

    def _backup_system_database(self, db_info, timestamp):
        """–†–µ–∑–µ—Ä–≤–Ω–æ–µ –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏–µ —Å–∏—Å—Ç–µ–º–Ω–æ–π –ë–î"""
        backups = []
        
        # –ï—Å–ª–∏ –Ω–µ—Ç –±–∞–∑ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Ä–µ–∑–µ—Ä–≤–Ω–æ–≥–æ –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏—è, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º
        if not db_info.get('databases'):
            logging.warning(f"–ù–µ—Ç –±–∞–∑ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Ä–µ–∑–µ—Ä–≤–Ω–æ–≥–æ –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏—è –≤ {db_info['type']} –Ω–∞ {db_info.get('host', 'localhost')}:{db_info.get('port', 'unknown')}")
            return backups
        
        for database in db_info.get('databases', []):
            try:
                if db_info['type'] == 'postgresql':
                    backup_file = f"pg_{db_info.get('host', 'localhost')}_{db_info.get('port', 5432)}_{database}_{timestamp}.sql"
                    backup_path = os.path.join(self.BACKUP_DIR, backup_file)
                    
                    cmd = [
                        'pg_dump',
                        '-h', db_info.get('host', 'localhost'),
                        '-p', str(db_info.get('port', 5432)),
                        '-U', 'postgres',
                        '--format=custom',
                        '--no-password',
                        '--file', backup_path,
                        database
                    ]
                    
                    env = os.environ.copy()
                    # –ü—ã—Ç–∞–µ–º—Å—è –±–µ–∑ –ø–∞—Ä–æ–ª—è, –ø–æ—Ç–æ–º —Å –ø—É—Å—Ç—ã–º –ø–∞—Ä–æ–ª–µ–º
                    env['PGPASSWORD'] = ''
                    
                elif db_info['type'] == 'mysql':
                    backup_file = f"mysql_{db_info.get('host', 'localhost')}_{db_info.get('port', 3306)}_{database}_{timestamp}.sql"
                    backup_path = os.path.join(self.BACKUP_DIR, backup_file)
                    
                    cmd = [
                        'mysqldump',
                        '-h', db_info.get('host', 'localhost'),
                        '-P', str(db_info.get('port', 3306)),
                        '-u', 'root',
                        '--single-transaction',
                        '--routines',
                        '--triggers',
                        database
                    ]
                    
                    env = os.environ.copy()
                    
                    with open(backup_path, 'w') as f:
                        result = subprocess.run(cmd, stdout=f, stderr=subprocess.PIPE, env=env, text=True)
                        
                elif db_info['type'] == 'mongodb':
                    backup_dir = f"mongo_{db_info.get('host', 'localhost')}_{db_info.get('port', 27017)}_{database}_{timestamp}"
                    backup_path = os.path.join(self.BACKUP_DIR, backup_dir)
                    os.makedirs(backup_path, exist_ok=True)
                    
                    cmd = [
                        'mongodump',
                        '--host', f"{db_info.get('host', 'localhost')}:{db_info.get('port', 27017)}",
                        '--db', database,
                        '--out', backup_path
                    ]
                    
                    env = os.environ.copy()
                    result = subprocess.run(cmd, capture_output=True, text=True, env=env)
                    
                elif db_info['type'] == 'redis':
                    backup_file = f"redis_{db_info.get('host', 'localhost')}_{db_info.get('port', 6379)}_{database}_{timestamp}.rdb"
                    backup_path = os.path.join(self.BACKUP_DIR, backup_file)
                    
                    # –î–ª—è Redis –∏—Å–ø–æ–ª—å–∑—É–µ–º BGSAVE –∏ –∫–æ–ø–∏—Ä—É–µ–º RDB —Ñ–∞–π–ª
                    cmd = [
                        'redis-cli',
                        '-h', db_info.get('host', 'localhost'),
                        '-p', str(db_info.get('port', 6379)),
                        'BGSAVE'
                    ]
                    
                    env = os.environ.copy()
                    result = subprocess.run(cmd, capture_output=True, text=True, env=env)
                    
                    if result.returncode == 0:
                        # –ñ–¥–µ–º –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è BGSAVE
                        import time
                        time.sleep(5)
                        
                        # –ö–æ–ø–∏—Ä—É–µ–º RDB —Ñ–∞–π–ª
                        try:
                            # –ü—ã—Ç–∞–µ–º—Å—è –Ω–∞–π—Ç–∏ RDB —Ñ–∞–π–ª Redis
                            rdb_locations = [
                                '/var/lib/redis/dump.rdb',
                                '/var/redis/dump.rdb', 
                                '/usr/local/var/db/redis/dump.rdb',
                                '/data/dump.rdb'
                            ]
                            
                            for rdb_path in rdb_locations:
                                if os.path.exists(rdb_path):
                                    import shutil
                                    shutil.copy2(rdb_path, backup_path)
                                    break
                        except Exception as e:
                            logging.error(f"–û—à–∏–±–∫–∞ –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏—è RDB —Ñ–∞–π–ª–∞: {e}")
                            continue
                
                elif db_info['type'] == 'sqlite':
                    backup_file = f"sqlite_{os.path.basename(db_info['file_path'])}_{timestamp}.db"
                    backup_path = os.path.join(self.BACKUP_DIR, backup_file)
                    
                    # –ü—Ä–æ—Å—Ç–æ–µ –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏–µ —Ñ–∞–π–ª–∞ SQLite
                    import shutil
                    shutil.copy2(db_info['file_path'], backup_path)
                    backups.append(backup_path)
                    continue
                
                elif db_info['type'] == 'elasticsearch':
                    # Elasticsearch snapshot —á–µ—Ä–µ–∑ API
                    backup_file = f"elasticsearch_{db_info.get('host', 'localhost')}_{db_info.get('port', 9200)}_{database}_{timestamp}.json"
                    backup_path = os.path.join(self.BACKUP_DIR, backup_file)
                    
                    try:
                        import requests
                        # –≠–∫—Å–ø–æ—Ä—Ç –∏–Ω–¥–µ–∫—Å–∞
                        url = f"http://{db_info.get('host', 'localhost')}:{db_info.get('port', 9200)}/{database}/_search"
                        params = {'size': 10000, 'scroll': '1m'}
                        response = requests.get(url, params=params, timeout=30)
                        
                        if response.status_code == 200:
                            with open(backup_path, 'w') as f:
                                json.dump(response.json(), f, indent=2)
                            backups.append(backup_path)
                            logging.info(f"–°–æ–∑–¥–∞–Ω–∞ —Ä–µ–∑–µ—Ä–≤–Ω–∞—è –∫–æ–ø–∏—è Elasticsearch: {backup_path}")
                        continue
                    except Exception as e:
                        logging.error(f"–û—à–∏–±–∫–∞ —Ä–µ–∑–µ—Ä–≤–Ω–æ–≥–æ –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏—è Elasticsearch {database}: {e}")
                        continue
                
                elif db_info['type'] == 'couchdb':
                    # CouchDB replication/export
                    backup_file = f"couchdb_{db_info.get('host', 'localhost')}_{db_info.get('port', 5984)}_{database}_{timestamp}.json"
                    backup_path = os.path.join(self.BACKUP_DIR, backup_file)
                    
                    try:
                        import requests
                        # –≠–∫—Å–ø–æ—Ä—Ç –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
                        url = f"http://{db_info.get('host', 'localhost')}:{db_info.get('port', 5984)}/{database}/_all_docs"
                        params = {'include_docs': True}
                        response = requests.get(url, params=params, timeout=30)
                        
                        if response.status_code == 200:
                            with open(backup_path, 'w') as f:
                                json.dump(response.json(), f, indent=2)
                            backups.append(backup_path)
                            logging.info(f"–°–æ–∑–¥–∞–Ω–∞ —Ä–µ–∑–µ—Ä–≤–Ω–∞—è –∫–æ–ø–∏—è CouchDB: {backup_path}")
                        continue
                    except Exception as e:
                        logging.error(f"–û—à–∏–±–∫–∞ —Ä–µ–∑–µ—Ä–≤–Ω–æ–≥–æ –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏—è CouchDB {database}: {e}")
                        continue
                
                else:
                    logging.warning(f"–†–µ–∑–µ—Ä–≤–Ω–æ–µ –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏–µ {db_info['type']} –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è")
                    continue
                
                # –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –∫–æ–º–∞–Ω–¥—ã –¥–ª—è PostgreSQL, MySQL, MongoDB, Redis
                if db_info['type'] in ['postgresql', 'mongodb', 'redis'] and db_info['type'] != 'mysql':
                    result = subprocess.run(cmd, capture_output=True, text=True, env=env)
                
                if result.returncode == 0:
                    logging.info(f"–°–æ–∑–¥–∞–Ω–∞ —Ä–µ–∑–µ—Ä–≤–Ω–∞—è –∫–æ–ø–∏—è: {backup_path}")
                    backups.append(backup_path)
                else:
                    logging.error(f"–û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è —Ä–µ–∑–µ—Ä–≤–Ω–æ–π –∫–æ–ø–∏–∏ {database}: {result.stderr}")
                    
            except Exception as e:
                logging.error(f"–û—à–∏–±–∫–∞ —Ä–µ–∑–µ—Ä–≤–Ω–æ–≥–æ –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏—è {database}: {e}")
        
        return backups

    def _backup_docker_database(self, db_info, timestamp):
        """–†–µ–∑–µ—Ä–≤–Ω–æ–µ –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏–µ –ë–î –≤ Docker"""
        backups = []
        
        try:
            container = self.docker_client.containers.get(db_info['container_id'])
            credentials = db_info.get('credentials', {})
            
            for database in db_info.get('databases', []):
                try:
                    if db_info['type'] == 'postgresql':
                        backup_file = f"docker_pg_{db_info['container_name']}_{database}_{timestamp}.sql"
                        backup_path = os.path.join(self.BACKUP_DIR, backup_file)
                        
                        cmd = [
                            'pg_dump',
                            '-U', credentials.get('user', 'postgres'),
                            '--format=custom',
                            database
                        ]
                        
                        env = {}
                        if credentials.get('password'):
                            env['PGPASSWORD'] = credentials['password']
                        
                    elif db_info['type'] == 'mysql':
                        backup_file = f"docker_mysql_{db_info['container_name']}_{database}_{timestamp}.sql"
                        backup_path = os.path.join(self.BACKUP_DIR, backup_file)
                        
                        cmd = [
                            'mysqldump',
                            '-u', credentials.get('user', 'root'),
                            '--single-transaction',
                            '--routines',
                            '--triggers',
                            database
                        ]
                        
                        env = {}
                        if credentials.get('password'):
                            cmd.append(f"-p{credentials['password']}")
                    
                    elif db_info['type'] == 'mongodb':
                        backup_file = f"docker_mongo_{db_info['container_name']}_{database}_{timestamp}.archive"
                        backup_path = os.path.join(self.BACKUP_DIR, backup_file)
                        
                        cmd = [
                            'mongodump',
                            '--db', database,
                            '--archive'
                        ]
                        env = {}
                    
                    # –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –∫–æ–º–∞–Ω–¥—ã –≤ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–µ
                    result = container.exec_run(cmd, environment=env)
                    
                    if result.exit_code == 0:
                        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –≤ —Ñ–∞–π–ª
                        with open(backup_path, 'wb') as f:
                            f.write(result.output)
                        
                        logging.info(f"–°–æ–∑–¥–∞–Ω–∞ —Ä–µ–∑–µ—Ä–≤–Ω–∞—è –∫–æ–ø–∏—è Docker: {backup_path}")
                        backups.append(backup_path)
                    else:
                        logging.error(f"–û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è —Ä–µ–∑–µ—Ä–≤–Ω–æ–π –∫–æ–ø–∏–∏ Docker {database}: {result.output.decode()}")
                        
                except Exception as e:
                    logging.error(f"–û—à–∏–±–∫–∞ —Ä–µ–∑–µ—Ä–≤–Ω–æ–≥–æ –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏—è Docker {database}: {e}")
                    
        except Exception as e:
            logging.error(f"–û—à–∏–±–∫–∞ —Ä–∞–±–æ—Ç—ã —Å –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–æ–º {db_info['container_name']}: {e}")
        
        return backups

    def upload_to_drive(self, file_path):
        """–ó–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–∞ –Ω–∞ Google Drive"""
        if not self.drive_service:
            logging.warning("Google Drive API –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω")
            return False
        
        try:
            filename = os.path.basename(file_path)
            
            file_metadata = {
                'name': filename,
                'parents': [self.DRIVE_FOLDER_ID] if self.DRIVE_FOLDER_ID else []
            }
            
            media = MediaFileUpload(file_path, resumable=True)
            
            file = self.drive_service.files().create(
                body=file_metadata,
                media_body=media,
                fields='id'
            ).execute()
            
            logging.info(f"–§–∞–π–ª {filename} –∑–∞–≥—Ä—É–∂–µ–Ω –Ω–∞ Google Drive. ID: {file.get('id')}")
            return True
            
        except Exception as e:
            logging.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –Ω–∞ Google Drive: {e}")
            return False

    def cleanup_old_backups(self, keep_days=7):
        """–û—á–∏—Å—Ç–∫–∞ —Å—Ç–∞—Ä—ã—Ö —Ä–µ–∑–µ—Ä–≤–Ω—ã—Ö –∫–æ–ø–∏–π"""
        try:
            current_time = time.time()
            cutoff_time = current_time - (keep_days * 24 * 60 * 60)
            
            for filename in os.listdir(self.BACKUP_DIR):
                file_path = os.path.join(self.BACKUP_DIR, filename)
                if os.path.isfile(file_path):
                    file_time = os.path.getctime(file_path)
                    if file_time < cutoff_time:
                        os.remove(file_path)
                        logging.info(f"–£–¥–∞–ª–µ–Ω —Å—Ç–∞—Ä—ã–π —Ñ–∞–π–ª: {filename}")
                        
        except Exception as e:
            logging.error(f"–û—à–∏–±–∫–∞ –æ—á–∏—Å—Ç–∫–∏ —Å—Ç–∞—Ä—ã—Ö —Ñ–∞–π–ª–æ–≤: {e}")

    def run_full_backup(self):
        """–í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –ø–æ–ª–Ω–æ–≥–æ —Ä–µ–∑–µ—Ä–≤–Ω–æ–≥–æ –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏—è"""
        logging.info("=" * 80)
        logging.info("üöÄ –ó–ê–ü–£–°–ö –ü–û–õ–ù–û–ì–û –†–ï–ó–ï–†–í–ù–û–ì–û –ö–û–ü–ò–†–û–í–ê–ù–ò–Ø")
        logging.info("=" * 80)
        
        start_time = datetime.now()
        
        # –≠—Ç–∞–ø 1: –û–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –≤—Å–µ—Ö –ë–î
        databases = self.discover_all_databases()
        
        if not databases:
            logging.warning("‚ùå –ë–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω—ã")
            return
        
        logging.info(f"\nüíæ –ù–∞—á–∏–Ω–∞–µ–º —Ä–µ–∑–µ—Ä–≤–Ω–æ–µ –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏–µ {len(databases)} –æ–±–Ω–∞—Ä—É–∂–µ–Ω–Ω—ã—Ö –°–£–ë–î...")
        
        total_backups = 0
        successful_backups = 0
        successful_uploads = 0
        failed_backups = []
        
        # –≠—Ç–∞–ø 2: –°–æ–∑–¥–∞–Ω–∏–µ —Ä–µ–∑–µ—Ä–≤–Ω—ã—Ö –∫–æ–ø–∏–π –¥–ª—è –∫–∞–∂–¥–æ–π –ë–î
        for i, db_info in enumerate(databases, 1):
            db_name = f"{db_info['type']} ({db_info.get('host', 'localhost')}:{db_info.get('port', 'unknown')})"
            logging.info(f"\nüì¶ [{i}/{len(databases)}] –†–µ–∑–µ—Ä–≤–Ω–æ–µ –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏–µ: {db_name}")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Ä–µ–∑–µ—Ä–≤–Ω–æ–≥–æ –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏—è
            db_count = len(db_info.get('databases', []))
            if db_count == 0:
                logging.warning(f"‚ö†Ô∏è –ù–µ—Ç –±–∞–∑ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Ä–µ–∑–µ—Ä–≤–Ω–æ–≥–æ –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏—è –≤ {db_name}")
                continue
            
            logging.info(f"üóÑÔ∏è –ë–∞–∑ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Ä–µ–∑–µ—Ä–≤–Ω–æ–≥–æ –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏—è: {db_count}")
            for db_name_item in db_info.get('databases', []):
                logging.info(f"   - {db_name_item}")
            
            try:
                backup_files = self.backup_database(db_info)
                
                if backup_files:
                    total_backups += len(backup_files)
                    successful_backups += len(backup_files)
                    
                    logging.info(f"‚úÖ –°–æ–∑–¥–∞–Ω–æ {len(backup_files)} —Ä–µ–∑–µ—Ä–≤–Ω—ã—Ö –∫–æ–ø–∏–π")
                    
                    # –ó–∞–≥—Ä—É–∑–∫–∞ –Ω–∞ Google Drive
                    if self.drive_service:
                        for backup_file in backup_files:
                            try:
                                if self.upload_to_drive(backup_file):
                                    successful_uploads += 1
                                    logging.info(f"‚òÅÔ∏è –ó–∞–≥—Ä—É–∂–µ–Ω–æ –Ω–∞ Google Drive: {os.path.basename(backup_file)}")
                                    
                                    # –£–¥–∞–ª–µ–Ω–∏–µ –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ —Ñ–∞–π–ª–∞ –ø–æ—Å–ª–µ —É—Å–ø–µ—à–Ω–æ–π –∑–∞–≥—Ä—É–∑–∫–∏
                                    try:
                                        if os.path.isfile(backup_file):
                                            os.remove(backup_file)
                                        elif os.path.isdir(backup_file):
                                            import shutil
                                            shutil.rmtree(backup_file)
                                        logging.debug(f"üóëÔ∏è –õ–æ–∫–∞–ª—å–Ω—ã–π —Ñ–∞–π–ª —É–¥–∞–ª–µ–Ω: {backup_file}")
                                    except Exception as e:
                                        logging.error(f"–û—à–∏–±–∫–∞ —É–¥–∞–ª–µ–Ω–∏—è –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ —Ñ–∞–π–ª–∞: {e}")
                                else:
                                    logging.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –Ω–∞ Google Drive: {os.path.basename(backup_file)}")
                            except Exception as e:
                                logging.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ñ–∞–π–ª–∞ {backup_file}: {e}")
                    else:
                        logging.warning("‚ö†Ô∏è Google Drive API –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω, —Ñ–∞–π–ª—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –ª–æ–∫–∞–ª—å–Ω–æ")
                else:
                    logging.error(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å —Ä–µ–∑–µ—Ä–≤–Ω—ã–µ –∫–æ–ø–∏–∏ –¥–ª—è {db_name}")
                    failed_backups.append(db_name)
                    
            except Exception as e:
                logging.error(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–µ–∑–µ—Ä–≤–Ω–æ–º –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏–∏ {db_name}: {e}")
                failed_backups.append(db_name)
        
        # –≠—Ç–∞–ø 3: –û—á–∏—Å—Ç–∫–∞ —Å—Ç–∞—Ä—ã—Ö —Ñ–∞–π–ª–æ–≤
        logging.info("\nüßπ –û—á–∏—Å—Ç–∫–∞ —Å—Ç–∞—Ä—ã—Ö —Ä–µ–∑–µ—Ä–≤–Ω—ã—Ö –∫–æ–ø–∏–π...")
        self.cleanup_old_backups()
        
        # –≠—Ç–∞–ø 4: –ò—Ç–æ–≥–æ–≤–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        end_time = datetime.now()
        duration = end_time - start_time
        
        logging.info("=" * 80)
        logging.info("üìä –ò–¢–û–ì–û–í–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê –†–ï–ó–ï–†–í–ù–û–ì–û –ö–û–ü–ò–†–û–í–ê–ù–ò–Ø")
        logging.info("=" * 80)
        logging.info(f"‚è±Ô∏è –í—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è: {duration}")
        logging.info(f"üîç –°–£–ë–î –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ: {len(databases)}")
        logging.info(f"üíæ –†–µ–∑–µ—Ä–≤–Ω—ã—Ö –∫–æ–ø–∏–π —Å–æ–∑–¥–∞–Ω–æ: {successful_backups}/{total_backups}")
        logging.info(f"‚òÅÔ∏è –§–∞–π–ª–æ–≤ –∑–∞–≥—Ä—É–∂–µ–Ω–æ –Ω–∞ Drive: {successful_uploads}")
        
        if failed_backups:
            logging.warning(f"‚ùå –û—à–∏–±–∫–∏ —Ä–µ–∑–µ—Ä–≤–Ω–æ–≥–æ –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏—è ({len(failed_backups)}):")
            for failed in failed_backups:
                logging.warning(f"   - {failed}")
        else:
            logging.info("‚úÖ –í—Å–µ —Ä–µ–∑–µ—Ä–≤–Ω—ã–µ –∫–æ–ø–∏–∏ —Å–æ–∑–¥–∞–Ω—ã —É—Å–ø–µ—à–Ω–æ!")
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
        self._save_backup_statistics({
            'timestamp': end_time.isoformat(),
            'duration_seconds': duration.total_seconds(),
            'databases_discovered': len(databases),
            'backups_created': successful_backups,
            'backups_uploaded': successful_uploads,
            'failed_backups': failed_backups,
            'success_rate': (successful_backups / total_backups * 100) if total_backups > 0 else 0
        })
        
        logging.info("=" * 80)

    def _save_backup_statistics(self, stats):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ —Ä–µ–∑–µ—Ä–≤–Ω–æ–≥–æ –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏—è"""
        try:
            stats_file = os.path.join(self.BACKUP_DIR, 'backup_statistics.json')
            
            # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
            if os.path.exists(stats_file):
                with open(stats_file, 'r', encoding='utf-8') as f:
                    all_stats = json.load(f)
            else:
                all_stats = []
            
            # –î–æ–±–∞–≤–ª—è–µ–º –Ω–æ–≤—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
            all_stats.append(stats)
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–æ–ª—å–∫–æ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 100 –∑–∞–ø–∏—Å–µ–π
            all_stats = all_stats[-100:]
            
            # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º –æ–±—Ä–∞—Ç–Ω–æ
            with open(stats_file, 'w', encoding='utf-8') as f:
                json.dump(all_stats, f, indent=2, ensure_ascii=False)
                
            logging.debug(f"–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤ {stats_file}")
            
        except Exception as e:
            logging.error(f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏: {e}")

    def generate_discovery_report(self):
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ –æ—Ç—á–µ—Ç–∞ –æ–± –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏–∏ –ë–î"""
        if not self.discovered_databases:
            logging.info("–°–Ω–∞—á–∞–ª–∞ –≤—ã–ø–æ–ª–Ω–∏—Ç–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –±–∞–∑ –¥–∞–Ω–Ω—ã—Ö")
            return
        
        logging.info("\n" + "=" * 80)
        logging.info("üìã –î–ï–¢–ê–õ–¨–ù–´–ô –û–¢–ß–ï–¢ –û–ë –û–ë–ù–ê–†–£–ñ–ï–ù–ò–ò –ë–î")
        logging.info("=" * 80)
        
        for i, db in enumerate(self.discovered_databases, 1):
            logging.info(f"\nüîπ [{i}] {db['type'].upper()}")
            logging.info(f"   üìç –†–∞—Å–ø–æ–ª–æ–∂–µ–Ω–∏–µ: {db.get('host', 'localhost')}:{db.get('port', 'N/A')}")
            logging.info(f"   üîç –ò—Å—Ç–æ—á–Ω–∏–∫ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è: {', '.join(db.get('sources', [db.get('source', 'unknown')]))}")
            
            if db.get('connection_tested'):
                status = "‚úÖ –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ —É—Å–ø–µ—à–Ω–æ" 
            elif db.get('connection_tested') is False:
                status = "‚ùå –û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è"
            else:
                status = "‚ùì –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –Ω–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–ª–æ—Å—å"
            logging.info(f"   üîó {status}")
            
            if db.get('auth_method'):
                logging.info(f"   üîê –ê—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏—è: {db['auth_method']}")
            
            databases = db.get('databases', [])
            if databases:
                logging.info(f"   üíæ –ë–∞–∑ –¥–∞–Ω–Ω—ã—Ö ({len(databases)}):")
                for db_name in databases:
                    logging.info(f"      - {db_name}")
            else:
                logging.info(f"   üíæ –ë–∞–∑ –¥–∞–Ω–Ω—ã—Ö: –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ")
            
            if db.get('note'):
                logging.info(f"   üìù –ü—Ä–∏–º–µ—á–∞–Ω–∏–µ: {db['note']}")
            
            # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –¥–ª—è Docker
            if db.get('source') == 'docker':
                logging.info(f"   üê≥ –ö–æ–Ω—Ç–µ–π–Ω–µ—Ä: {db.get('container_name', 'N/A')}")
                logging.info(f"   üì¶ –û–±—Ä–∞–∑: {db.get('image', 'N/A')}")
            
            # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –¥–ª—è SQLite
            if db.get('type') == 'sqlite':
                file_path = db.get('file_path', 'N/A')
                file_size = db.get('size', 0)
                logging.info(f"   üìÅ –§–∞–π–ª: {file_path}")
                logging.info(f"   üìè –†–∞–∑–º–µ—Ä: {file_size / 1024 / 1024:.2f} MB")
        
        logging.info("=" * 80)

    def test_database_connections(self):
        """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–π –∫–æ –≤—Å–µ–º –æ–±–Ω–∞—Ä—É–∂–µ–Ω–Ω—ã–º –ë–î"""
        if not self.discovered_databases:
            logging.info("–°–Ω–∞—á–∞–ª–∞ –≤—ã–ø–æ–ª–Ω–∏—Ç–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –±–∞–∑ –¥–∞–Ω–Ω—ã—Ö")
            return
        
        logging.info("\nüß™ –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï –ü–û–î–ö–õ–Æ–ß–ï–ù–ò–ô –ö –ë–î")
        logging.info("=" * 50)
        
        success_count = 0
        total_count = len(self.discovered_databases)
        
        for db in self.discovered_databases:
            db_name = f"{db['type']} ({db.get('host', 'localhost')}:{db.get('port', 'N/A')})"
            
            try:
                if db['type'] == 'postgresql':
                    success = self._test_postgresql_connection(db)
                elif db['type'] == 'mysql':
                    success = self._test_mysql_connection(db)
                elif db['type'] == 'mongodb':
                    success = self._test_mongodb_connection(db)
                elif db['type'] == 'redis':
                    success = self._test_redis_connection(db)
                elif db['type'] == 'sqlite':
                    success = os.path.exists(db.get('file_path', ''))
                else:
                    success = False
                    
                if success:
                    logging.info(f"‚úÖ {db_name}")
                    success_count += 1
                else:
                    logging.error(f"‚ùå {db_name}")
                    
            except Exception as e:
                logging.error(f"‚ùå {db_name}: {e}")
        
        logging.info("=" * 50)
        logging.info(f"üìä –†–µ–∑—É–ª—å—Ç–∞—Ç: {success_count}/{total_count} —É—Å–ø–µ—à–Ω—ã—Ö –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–π")

    def _test_postgresql_connection(self, db):
        """–¢–µ—Å—Ç –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ PostgreSQL"""
        try:
            cmd = ['psql', '-h', db.get('host', 'localhost'), '-p', str(db.get('port', 5432)),
                   '-U', 'postgres', '-d', 'template1', '-c', 'SELECT version();']
            result = subprocess.run(cmd, capture_output=True, text=True, timeout=5,
                                  env={**os.environ, 'PGPASSWORD': ''})
            return result.returncode == 0
        except:
            return False

    def _test_mysql_connection(self, db):
        """–¢–µ—Å—Ç –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ MySQL"""
        try:
            cmd = ['mysql', '-h', db.get('host', 'localhost'), '-P', str(db.get('port', 3306)),
                   '-u', 'root', '-e', 'SELECT VERSION();']
            result = subprocess.run(cmd, capture_output=True, text=True, timeout=5)
            return result.returncode == 0
        except:
            return False

    def _test_mongodb_connection(self, db):
        """–¢–µ—Å—Ç –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ MongoDB"""
        try:
            cmd = ['mongo', '--host', f"{db.get('host', 'localhost')}:{db.get('port', 27017)}",
                   '--eval', 'db.version()', '--quiet']
            result = subprocess.run(cmd, capture_output=True, text=True, timeout=5)
            return result.returncode == 0
        except:
            return False

    def _test_redis_connection(self, db):
        """–¢–µ—Å—Ç –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ Redis"""
        try:
            cmd = ['redis-cli', '-h', db.get('host', 'localhost'), '-p', str(db.get('port', 6379)), 'ping']
            result = subprocess.run(cmd, capture_output=True, text=True, timeout=5)
            return result.returncode == 0 and 'PONG' in result.stdout
        except:
            return False

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    import argparse
    
    # –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ –ª–æ–≥–æ—Ç–∏–ø–∞ –ø—Ä–∏ –∑–∞–ø—É—Å–∫–µ
    print_logo()
    
    parser = argparse.ArgumentParser(description='DumpItAll - –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ —Ä–µ–∑–µ—Ä–≤–Ω–æ–≥–æ –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏—è –ë–î')
    parser.add_argument('--scan-only', action='store_true', 
                       help='–¢–æ–ª—å–∫–æ —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –ë–î –±–µ–∑ —Ä–µ–∑–µ—Ä–≤–Ω–æ–≥–æ –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏—è')
    parser.add_argument('--test-connections', action='store_true',
                       help='–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–π –∫ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–Ω—ã–º –ë–î')
    parser.add_argument('--backup-once', action='store_true',
                       help='–û–¥–Ω–æ–∫—Ä–∞—Ç–Ω–æ–µ —Ä–µ–∑–µ—Ä–≤–Ω–æ–µ –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏–µ –±–µ–∑ –ø–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫–∞')
    parser.add_argument('--daemon', action='store_true',
                       help='–ó–∞–ø—É—Å–∫ –≤ —Ä–µ–∂–∏–º–µ –¥–µ–º–æ–Ω–∞ —Å –ø–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫–æ–º')
    parser.add_argument('--interval', type=int, default=30,
                       help='–ò–Ω—Ç–µ—Ä–≤–∞–ª —Ä–µ–∑–µ—Ä–≤–Ω–æ–≥–æ –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏—è –≤ –º–∏–Ω—É—Ç–∞—Ö (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: 30)')
    parser.add_argument('--config', type=str, default='.env',
                       help='–ü—É—Ç—å –∫ —Ñ–∞–π–ª—É –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: .env)')
    parser.add_argument('--log-level', choices=['DEBUG', 'INFO', 'WARNING', 'ERROR'], 
                       default='INFO', help='–£—Ä–æ–≤–µ–Ω—å –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è')
    
    args = parser.parse_args()
    
    # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —É—Ä–æ–≤–Ω—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
    logging.getLogger().setLevel(getattr(logging, args.log_level))
    
    # –ó–∞–≥—Ä—É–∑–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
    if os.path.exists(args.config):
        from dotenv import load_dotenv
        load_dotenv(args.config)
    
    backup_manager = UniversalBackup()
    
    if args.scan_only:
        # –¢–æ–ª—å–∫–æ —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ
        logging.info("üîç –†–µ–∂–∏–º: —Ç–æ–ª—å–∫–æ —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –ë–î")
        backup_manager.discover_all_databases()
        backup_manager.generate_discovery_report()
        
    elif args.test_connections:
        # –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–π
        logging.info("üß™ –†–µ–∂–∏–º: —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–π")
        backup_manager.discover_all_databases()
        backup_manager.test_database_connections()
        
    elif args.backup_once:
        # –û–¥–Ω–æ–∫—Ä–∞—Ç–Ω–æ–µ —Ä–µ–∑–µ—Ä–≤–Ω–æ–µ –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏–µ
        logging.info("üíæ –†–µ–∂–∏–º: –æ–¥–Ω–æ–∫—Ä–∞—Ç–Ω–æ–µ —Ä–µ–∑–µ—Ä–≤–Ω–æ–µ –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏–µ")
        backup_manager.run_full_backup()
        
    else:
        # –†–µ–∂–∏–º –¥–µ–º–æ–Ω–∞ —Å –ø–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫–æ–º (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é)
        logging.info("ü§ñ –†–µ–∂–∏–º: –¥–µ–º–æ–Ω —Å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–º —Ä–µ–∑–µ—Ä–≤–Ω—ã–º –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏–µ–º")
        
        # –ü–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è
        schedule.every(args.interval).minutes.do(backup_manager.run_full_backup)
        
        logging.info(f"üóÑÔ∏è DumpItAll —Å–ª—É–∂–±–∞ –∑–∞–ø—É—â–µ–Ω–∞")
        logging.info(f"–†–µ–∑–µ—Ä–≤–Ω–æ–µ –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–∞–∂–¥—ã–µ {args.interval} –º–∏–Ω—É—Ç")
        
        # –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –ø–µ—Ä–≤–æ–≥–æ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è –∏ –±—ç–∫–∞–ø–∞
        backup_manager.run_full_backup()
        
        # –û—Å–Ω–æ–≤–Ω–æ–π —Ü–∏–∫–ª
        try:
            while True:
                schedule.run_pending()
                time.sleep(60)  # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–∞–∂–¥—É—é –º–∏–Ω—É—Ç—É
        except KeyboardInterrupt:
            logging.info("–î–µ–º–æ–Ω –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")

if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        logging.info("–°–ª—É–∂–±–∞ –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
    except Exception as e:
        logging.error(f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}")
        import traceback
        logging.error(traceback.format_exc())
